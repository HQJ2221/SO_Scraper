{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Week 11: Data Preprocessing\n",
    "\n",
    "- 本周我们初步完成了将 68363 条从 StackOverflow 上爬取的数据进行预处理的工作\n",
    "- 由于爬取数据时没有直接转为易于模型训练的 json 格式，而是使用 txt 用自定义的格式存储，所以为了方便后续的数据处理，我们需要将这些数据转为 json 格式（目标：能使用 `json.load(file.read())` 读取数据）\n",
    "- 因为爬取数据时将每条帖子创建一个 txt 文件存储，所以导致 QA 文件夹内文件过多，不易管理，所以用 `merge_file` 将多个帖子存在一个文件中（之所以不一次性将所有帖子存在同一个文件，是为了方便 debug 检查 json 格式），并进行初步的格式化（包括调整引号和保留一个 solution 等）。\n",
    "- 然后通过 `preprocessing_file` 尝试将多个文件的 data 合并到一个 List 中，并筛选掉空回复的帖子，然后转存为 json 文件。\n",
    "- 最后就能将所有的数据存到一个 json 文件中，并确保能正确读取。结果：数据可以用 `json.load(file.read())` 读取，且可以转化为 DataFrame 等格式，方便模型使用。\n",
    "\n",
    "Origin total data: 68363\n",
    "\n",
    "Final total data: 51182\n",
    "\n",
    "<font color=red>注意！</font> 运行本脚本必须确保将本文件置于与 qa 文件夹同目录的另一文件夹中！（如下）\n",
    "\n",
    "```\n",
    "|_qa\n",
    "|\n",
    "|_XXX\n",
    "  |_preprocessing_data.ipynb\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68a606d24a41c368"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T06:39:29.722658800Z",
     "start_time": "2024-11-20T06:39:29.706261600Z"
    }
   },
   "id": "88fd3c8240774d70"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "merge_file.py\n",
    "将每 1000 条帖子合并成一个文件，并将每个文件的数据格式化，对多个 solutions 的帖子，只筛选出第一条 solution\n",
    "'''\n",
    "\n",
    "'''\n",
    "merge several files to one file, by the way formatting them to \"json friendly\" files\n",
    "'''\n",
    "def merge_txt_files(source_folder, output_folder, files_per_merge=1000):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    file_count = 0\n",
    "    merge_count = 0\n",
    "    outfile = None\n",
    "\n",
    "    for root, _, files in os.walk(source_folder):  # 遍历 qa 的所有文件\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                if file_count % files_per_merge == 0:  # 当计数为 0 或满 1000 时，创建新文件\n",
    "                    if outfile:\n",
    "                        outfile.write(\"]\\n\")\n",
    "                        print(f\"File {output_file} created.\")\n",
    "                        outfile.close()\n",
    "                    merge_count += 1\n",
    "                    output_file = os.path.join(output_folder, f'merged_{merge_count}.json')\n",
    "                    outfile = open(output_file, 'w', encoding='utf-8')  # 打开输出文件的输出流\n",
    "                    outfile.write(\"[\\n\")\n",
    "                else:\n",
    "                    if outfile:\n",
    "                        outfile.write(\",\\n\")\n",
    "\n",
    "\n",
    "                file_path = os.path.join(root, file)  # 输入文件的路径\n",
    "                with open(file_path, 'r', encoding='utf-8') as infile:  # 打开输入文件的输入流\n",
    "                    problem, solution = formatting(infile)  # 格式化文件内容\n",
    "                    data = {\"problem\": problem, \"solution\": solution}  # 采用字典作为 json 输入元素\n",
    "                    json.dump(data, outfile, ensure_ascii=False, indent=4)  # 将字典转为 json 格式写入输出文件\n",
    "\n",
    "                file_count += 1\n",
    "\n",
    "    if outfile:\n",
    "        outfile.write(\"]\\n\")\n",
    "        print(f\"File {output_file} created.\")\n",
    "        outfile.close()\n",
    "\n",
    "'''\n",
    "Formatting the file content to json friendly format\n",
    "'''\n",
    "def formatting(file):\n",
    "    mode = 0\n",
    "    space_num = 0\n",
    "    pbs = \"\"  # 存储问题\n",
    "    slt = \"\"  # 存储回答\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line:\n",
    "            break\n",
    "\n",
    "        line = line.strip()\n",
    "        # 将单引号转为双引号（json 的 key 必须是双引号）\n",
    "        line = re.sub(r\"'problems'\", \"\\\"problems\\\"\", line)\n",
    "        line = re.sub(r\"'solutions'\", \"\\\"solutions\\\"\", line)\n",
    "\n",
    "        for match in re.finditer(r\"('(.*)')|(\\\"(.*)\\\")\", line):  # 检测最外围的单引号或双引号作为本行内容\n",
    "            raw = match.group(0).strip()\n",
    "            # 去除外围引号\n",
    "            if raw[0] == \"'\" and raw[-1] == \"'\":\n",
    "                raw = raw[1:-1]\n",
    "            elif raw[0] == '\"' and raw[-1] == '\"':\n",
    "                raw = raw[1:-1]\n",
    "            \n",
    "            # 去除内容中的 \"\\n\"，替换为真正的换行符；对于多行换行符，转成一行\n",
    "            if raw == \"\\\\n\":\n",
    "                space_num += 1\n",
    "                continue\n",
    "            else:\n",
    "                if space_num > 1:\n",
    "                    raw = \"\\n\" + raw\n",
    "                space_num = 0\n",
    "\n",
    "            if raw[-2:] == \"\\\\n\":\n",
    "                raw = raw[:-2] + \"\\n\"\n",
    "\n",
    "            if raw == \"solutions\" or raw == \"problems\":\n",
    "                if raw == \"solutions\":\n",
    "                    mode = 1\n",
    "                continue\n",
    "            \n",
    "            # 特殊处理（如果没有遇到内容中单引号变为“\\'”的情况可以注释）\n",
    "            raw = raw.replace(\"\\\\'\", \"'\")\n",
    "            \n",
    "            # 对于多个 solutions，只取第一个\n",
    "            if mode == 1 and raw == \"............................................................\":\n",
    "                return pbs, slt\n",
    "\n",
    "            if mode == 0:\n",
    "                pbs += raw\n",
    "            else:\n",
    "                slt += raw\n",
    "\n",
    "    return pbs, slt\n",
    "\n",
    "# main\n",
    "source_folder = '../qa'  # 保证文件位置\n",
    "output_folder = 'merged_files'\n",
    "merge_txt_files(source_folder, output_folder)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14fb790777be0d10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "preprocessing_file.py\n",
    "将多个文件的数据合并到一个 List 中，并筛选掉空回复的帖子，然后转存为 json 文件\n",
    "'''\n",
    "def filter_null_solution(src_folder, dst_folder, min_merge_per_file=1600):\n",
    "    total_len = 0\n",
    "    test_len = 0\n",
    "    merge_num = 1\n",
    "    if not os.path.exists(dst_folder):\n",
    "        os.mkdir(dst_folder)\n",
    "    outfile = open(f\"{dst_folder}/fil_{merge_num}.json\", \"w\", encoding=\"utf-8\")\n",
    "    tot_data = []\n",
    "\n",
    "    for root, _, files in os.walk(src_folder):  # 遍历 merged_files 的所有文件\n",
    "        for file in files:\n",
    "            if test_len > min_merge_per_file:  # 确保每个文件至少有 min_merge_per_file 条数据\n",
    "                print(f\"File fil_{merge_num}.json has {test_len} items.\")\n",
    "                merge_num += 1\n",
    "                test_len = 0\n",
    "                json.dump(tot_data, outfile, ensure_ascii=False, indent=4)\n",
    "                outfile.close()\n",
    "                outfile = open(f\"{dst_folder}/fil_{merge_num}.json\", \"w\", encoding=\"utf-8\")\n",
    "                tot_data = []\n",
    "\n",
    "            with open(os.path.join(root, file), \"r\") as f:\n",
    "                data = json.loads(f.read())\n",
    "            filtered_data = [item for item in data if item.get(\"solution\")]  # 筛选掉空回复的帖子\n",
    "            # print(f\"{file}: {len(filtered_data)} data after filter.\")\n",
    "            test_len += len(filtered_data)\n",
    "            total_len += len(data)\n",
    "            tot_data.extend(filtered_data)\n",
    "\n",
    "    print(f\"File fil_{merge_num}.json has {test_len} items.\")\n",
    "    json.dump(tot_data, outfile, ensure_ascii=False, indent=4)\n",
    "    outfile.close()\n",
    "    print(f\"Total data: {total_len}\")\n",
    "\n",
    "# main\n",
    "filter_null_solution(\"merged_files\", \"filtered_files\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d12d73c446a368f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "load_data.py\n",
    "将所有数据存到一个 json 文件中，并确保能正确读取\n",
    "'''\n",
    "data = []\n",
    "for root, _, files in os.walk(\"filtered_files\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".json\"):\n",
    "            with open(os.path.join(root, file), \"r\") as f:\n",
    "                # print(f\"Reading file {file}\")\n",
    "                data.extend(json.loads(f.read()))\n",
    "\n",
    "print(f\"Total data: {len(data)}\")\n",
    "\n",
    "# 将所有的数据存到一个 json 文件中\n",
    "with open(\"all_data.json\", 'w') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a17b1a90cf85f95"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
